{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irK7NAlule9a"
   },
   "outputs": [],
   "source": [
    "!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMaQqOJbaP3F"
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ujbs5BSaZ5VY"
   },
   "outputs": [],
   "source": [
    "class topic_modeling():\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.name = filename\n",
    "        self.df = pd.read_csv(filename+\".csv\")\n",
    "        self.cluster_df = pd.DataFrame()\n",
    "        self.df_info = pd.DataFrame()\n",
    "        self.topics = ''\n",
    "        self.topic_model = ''\n",
    "        self.probs = 0\n",
    "        \n",
    "    def get_dataframe(self):\n",
    "        return self.df\n",
    "\n",
    "    def display(self):\n",
    "        display(self.df.head())\n",
    "    \n",
    "    #Function to do topic modeling using BERT\n",
    "    def bert_topic_modeling(self, min_cluster_size = 2500,min_samples=1000,n_neighbors=200):\n",
    "        vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "        umap_model = UMAP(n_neighbors=200, n_components=10, min_dist=0.0, metric='cosine', random_state=42)\n",
    "        hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "        seed_topic_list = [[\"trump\", \"donald\", \"conservative\"],\n",
    "                       [\"biden\", \"joe\", \"china\", \"blue\",\"liberal\"]]\n",
    "        self.topic_model = BERTopic(vectorizer_model=vectorizer_model,language=\"english\", calculate_probabilities=True, verbose=True, hdbscan_model = hdbscan_model, umap_model = umap_model, seed_topic_list=seed_topic_list)\n",
    "        self.topics, self.probs = self.topic_model.fit_transform(self.df['text'])\n",
    "    \n",
    "    #Save models is used to save the topic models, clustered topic model and \n",
    "    def save_models(self, name):\n",
    "        self.topic_model.save(name)\n",
    "        self.cluster_df = pd.DataFrame(data={\"docs\":self.df['text'],\"topics\":self.topics})\n",
    "        self.cluster_df.to_csv(name+\"_dataframe\"+\".csv\")\n",
    "        self.df_info = self.topic_model.get_topic_info()\n",
    "        self.df_info.to_csv(name+\"_info\"+\".csv\")\n",
    "    \n",
    "    def load_model(self,filename):\n",
    "        #topic_model = BERTopic.load(filename)\n",
    "        self.cluster_df = pd.read_csv(filename+\"_dataframe\"+\".csv\")\n",
    "        self.df_info = pd.read_csv(filename+\"_info\"+\".csv\")\n",
    "        \n",
    "    def analyze_topics(self,n,visualise_topics=False,visualize_hierarchy=False):\n",
    "        print(\"Displaying the types of topics\")\n",
    "        display(self.topic_model.get_topic_info())\n",
    "        print(\"Displaying the import topic keyword probability\")\n",
    "        display(self.topic_model.get_topic(n))\n",
    "        if visualise_topics:\n",
    "            self.topic_model.visualize_topics()\n",
    "        if visualize_hierarchy:\n",
    "            self.topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al1p16ch0nQm",
    "outputId": "88ebf7ac-e979-4126-8709-0cf3d37754f8"
   },
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fxr49DKZ5VZ"
   },
   "outputs": [],
   "source": [
    "obj = topic_modeling('trimmed_pre_election_punctuation_CNN_20')\n",
    "obj.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jvHCVqyZ5Va"
   },
   "outputs": [],
   "source": [
    "obj.bert_topic_modeling() # Deafult parameters (min_cluster_size = 2500,min_samples=1000,n_neighbors=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRYXpWppb1-u"
   },
   "outputs": [],
   "source": [
    "obj.save_models(\"topic_model_2500\") # Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qXfMjTui9__"
   },
   "outputs": [],
   "source": [
    "obj.load_model(\"topic_model_2500\") #Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzQoaM4scI2P"
   },
   "outputs": [],
   "source": [
    "obj.analyze_topics(0) # Default parameters (get_topic = n,visualise_topics=False,visualize_hierarchy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"topic_model_2500_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topics'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
