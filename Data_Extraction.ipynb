{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09080de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Extraced from CNN, FOX and MSNBC folders from the files in the local computer \n",
    "# (The original data files are really large to be uploaded along with the project files)\n",
    "channel = \"CNN\"\n",
    "\n",
    "party_words = ['biden', 'joe', 'joebiden', 'donald', 'trump', 'donaldtrump']\n",
    "              \n",
    "keywords = ['win', 'won', 'vote', 'winner']\n",
    "\n",
    "def find_word(text):\n",
    "    py_stem = PorterStemmer ()\n",
    "    token = [py_stem.stem(word) for word in text.split()]\n",
    "    if any(word in token for word in party_words) and any(word in token for word in keywords): #checking if any one of the keyword matches the string\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "dir_name = f\"{channel}_merged/{channel}_parsed/\"\n",
    "comment_set = []\n",
    "\n",
    "cnt = 0 \n",
    "st = time.time()\n",
    "for file in os.listdir(dir_name+\"metadata/\"):\n",
    "    video_id = None\n",
    "    if file.endswith(\".csv\"):\n",
    "        video_id = file[:-len(\"_metadata.csv\")]\n",
    "        # print(video_id)\n",
    "\n",
    "    if video_id is None: continue\n",
    "    \n",
    "    with open(dir_name+\"jsonbyline/\"+video_id+\"_jsonbyline.txt\", \"r\", encoding='utf-8') as fi:\n",
    "        ids, text = [], []\n",
    "        # print(video_id)\n",
    "        for line in fi:\n",
    "            cnt+=1\n",
    "            # x = None\n",
    "            if \", 'text': \" in line:\n",
    "\n",
    "                dictionary = ast.literal_eval(line)\n",
    "                dictionary['text'] = dictionary['text'].encode('unicode-escape').decode('ascii')\n",
    "                #print(dictionary)\n",
    "                x = dictionary['commentId']\n",
    "                #print(x)\n",
    "                y = dictionary['text']\n",
    "                #print(y)\n",
    "                if find_word(y):\n",
    "                    ids.append(x)\n",
    "                    text.append(y)\n",
    "\n",
    "            else:\n",
    "\n",
    "                dictionary = ast.literal_eval(line)\n",
    "                dictionary['text'] = dictionary['text'].encode('unicode-escape').decode('ascii')\n",
    "                #print(dictionary)\n",
    "                x = dictionary['commentId']\n",
    "                #print(x)\n",
    "                y = dictionary['text']\n",
    "                #print(y)\n",
    "                if find_word(y):\n",
    "                    ids.append(x)\n",
    "                    text.append(y)\n",
    "        df = pd.DataFrame()\n",
    "        df[\"commentId\"] = ids\n",
    "        df[\"text\"] = text\n",
    "        df = df.drop_duplicates(subset=[\"commentId\"], keep='first')\n",
    "        df[\"commentId\"] =  df[\"commentId\"].astype(str)\n",
    "\n",
    "        _df = pd.read_csv(dir_name+\"metadata/\"+video_id+\"_metadata.csv\")\n",
    "        _df = _df.drop_duplicates(subset=[\"commentId\"], keep='first')\n",
    "        _df[\"commentId\"] =  _df[\"commentId\"].astype(str)\n",
    "        \n",
    "        _df[\"timeline\"] = _df[\"publishedAt\"].str.slice(stop=10)\n",
    "        _df[\"timeline\"] = pd.to_datetime(_df[\"timeline\"], format=\"%Y-%m-%d\")\n",
    "        _df = _df[(_df[\"timeline\"] > '2020-10-19') & (_df[\"timeline\"] < '2020-11-08')]\n",
    "        df = df.join(_df.set_index(\"commentId\"), on=\"commentId\")\n",
    "        \n",
    "        df = df[[\"videoId\", \"commentId\", \"text\", \"likeCount\", \"totalReplyCount\", \"timeline\"]]\n",
    "        \n",
    "        # if video_id in big_data:\n",
    "        #     df[\"videoDate\"] = big_data[video_id][\"date\"]\n",
    "        # else: df[\"videoDate\"] = -1\n",
    "\n",
    "        # remove duplicate comments\n",
    "        \n",
    "        df.to_csv(f'forecasting_{channel}.csv', mode='a', index=False, header=not os.path.exists(f'forecasting_{channel}.csv'))\n",
    "en = time.time()\n",
    "print(\"first pass: \", en-st)\n",
    "print(cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
